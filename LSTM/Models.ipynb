{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests performance of LSTM models created in LSTM.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, BatchNormalization\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_data = pd.read_csv('TRAIN_DATA.csv')\n",
    "    train_X = train_data.iloc[:, :-1]\n",
    "    train_y = train_data[train_data.columns[-1]]\n",
    "    val_data = pd.read_csv('VAL_DATA.csv')\n",
    "    val_X = val_data.iloc[:, :-1]\n",
    "    val_y = val_data[val_data.columns[-1]]\n",
    "    test_data = pd.read_csv('TEST_DATA.csv')\n",
    "    test_X = test_data.iloc[:, :-1]\n",
    "    test_y = test_data[test_data.columns[-1]]\n",
    "\n",
    "    train_X = Convert(train_X)\n",
    "    val_X = Convert(val_X)\n",
    "    test_X = Convert(test_X)\n",
    "    return train_X, train_y, val_X, val_y, test_X, test_y\n",
    "\n",
    "def Convert(x):\n",
    "    data = []\n",
    "    for index, row in x.iterrows():\n",
    "        row_lst = []\n",
    "        for post in row:\n",
    "            if isinstance(post, float) and np.isnan(post):\n",
    "                row_lst.append(np.zeros(768))\n",
    "            else:\n",
    "                a = post.split()\n",
    "                lst = []\n",
    "                for val in a:\n",
    "                    if val != '[' and val[-1] != ']' and val[0] != '[':\n",
    "                        b = float(val)\n",
    "                        lst.append(b)\n",
    "                    elif val[-1] == ']' and len(val) > 1:\n",
    "                        val = val[:-1]\n",
    "                        b = float(val)\n",
    "                        lst.append(b)\n",
    "                    elif val[0] == '[' and len(val) > 1:\n",
    "                        val = val[1:]\n",
    "                        b = float(val)\n",
    "                        lst.append(b)\n",
    "                row_lst.append(np.array(lst))\n",
    "        data.append(np.array(row_lst))\n",
    "    parsed_test_x = np.array(data)\n",
    "    return parsed_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, val_X, val_y, test_X, test_y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Best Model 1\n",
    "Running Model 1 in LSTM.ipynb 10 times and averaging the statistics. Note each iteration does not show the output because of the formatting. I fixed it for Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLSTM(X_data, loss):\n",
    "    model = Sequential()\n",
    "\n",
    "    # layer 1: LSTM\n",
    "    model.add(LSTM(400, input_shape=(X_data.shape[1], X_data.shape[2])\n",
    "                   , return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # layer 2: LSTM\n",
    "    model.add(LSTM(150, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # output\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLossModel(train_X, train_y, loss):\n",
    "    model = createLSTM(train_X, loss)\n",
    "    # fit network\n",
    "    history = model.fit(train_X, train_y, epochs=40, batch_size=120, validation_data=(val_X, val_y), verbose=0)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400/3400 [==============================] - 11s 3ms/step\n",
      "Iteration: 0, precision: 0, recall: 0, F1: 0, accuracy: 0\n",
      "3400/3400 [==============================] - 10s 3ms/step\n",
      "Iteration: 1, precision: 0, recall: 0, F1: 0, accuracy: 0\n",
      "3400/3400 [==============================] - 9s 3ms/step\n",
      "Iteration: 2, precision: 0, recall: 0, F1: 0, accuracy: 0\n",
      "3400/3400 [==============================] - 10s 3ms/step\n",
      "Iteration: 3, precision: 0, recall: 0, F1: 0, accuracy: 0\n",
      "3400/3400 [==============================] - 10s 3ms/step\n",
      "Iteration: 4, precision: 0, recall: 0, F1: 0, accuracy: 0\n",
      "3400/3400 [==============================] - 10s 3ms/step\n",
      "Iteration: 5, precision: 0, recall: 0, F1: 0, accuracy: 0\n",
      "3400/3400 [==============================] - 10s 3ms/step\n",
      "Iteration: 6, precision: 0, recall: 0, F1: 0, accuracy: 0\n",
      "3400/3400 [==============================] - 10s 3ms/step\n",
      "Iteration: 7, precision: 0, recall: 0, F1: 0, accuracy: 0\n",
      "3400/3400 [==============================] - 10s 3ms/step\n",
      "Iteration: 8, precision: 0, recall: 0, F1: 0, accuracy: 0\n",
      "3400/3400 [==============================] - 11s 3ms/step\n",
      "Iteration: 9, precision: 0, recall: 0, F1: 0, accuracy: 0\n",
      "Average, precision: 91, recall: 91, F1: 91, accuracy: 94\n"
     ]
    }
   ],
   "source": [
    "loss = 'mean_squared_error'\n",
    "num_of_test_samples = test_y.shape[0]\n",
    "batch_size = 120\n",
    "n = 10\n",
    "\n",
    "precision_total = 0\n",
    "recall_total = 0\n",
    "f1_total = 0\n",
    "accuracy_total = 0\n",
    "\n",
    "for i in range(n):\n",
    "    model = getLossModel(train_X, train_y, loss)\n",
    "    test_mse = model.evaluate(test_X, test_y, verbose=1)\n",
    "    y_pred = model.predict_classes(test_X, num_of_test_samples // batch_size+1)\n",
    "    report = classification_report(test_y, y_pred, target_names=target_names, output_dict=True)\n",
    "    precision = report['macro avg']['precision']\n",
    "    recall = report['macro avg']['recall']\n",
    "    f1 = report['macro avg']['f1-score']\n",
    "    accuracy = report['accuracy']\n",
    "    \n",
    "    print(\"Iteration: %d, precision: %d, recall: %d, F1: %d, accuracy: %d\" % (i, precision, recall, f1, accuracy))\n",
    "    \n",
    "    precision_total += precision\n",
    "    recall_total += recall\n",
    "    f1_total += f1\n",
    "    accuracy_total += accuracy\n",
    "\n",
    "precision_total = precision_total / n * 100\n",
    "recall_total = recall_total / n * 100\n",
    "f1_total = f1_total / n * 100\n",
    "accuracy_total = accuracy_total / n * 100\n",
    "print(\"Average, precision: %d, recall: %d, F1: %d, accuracy: %d\" % (precision_total, recall_total, f1_total, accuracy_total))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Best Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLSTM2(X_data, loss):\n",
    "    model = Sequential()\n",
    "\n",
    "    # layer 1: LSTM\n",
    "    model.add(LSTM(768, input_shape=(X_data.shape[1], X_data.shape[2]), return_sequences=False))\n",
    "    \n",
    "    # output\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLossModel2(train_X, train_y, loss):\n",
    "    model = createLSTM2(train_X, loss)\n",
    "    # fit network\n",
    "    history = model.fit(train_X, train_y, epochs=40, batch_size=120, validation_data=(val_X, val_y), verbose=0)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400/3400 [==============================] - 10s 3ms/step\n",
      "Iteration: 0, precision: 0.93, recall: 0.94, F1: 0.93, accuracy: 0.96\n",
      "3400/3400 [==============================] - 11s 3ms/step\n",
      "Iteration: 1, precision: 0.94, recall: 0.93, F1: 0.94, accuracy: 0.96\n",
      "3400/3400 [==============================] - 10s 3ms/step\n",
      "Iteration: 2, precision: 0.93, recall: 0.94, F1: 0.93, accuracy: 0.96\n",
      "3400/3400 [==============================] - 10s 3ms/step\n",
      "Iteration: 3, precision: 0.94, recall: 0.93, F1: 0.93, accuracy: 0.96\n",
      "3400/3400 [==============================] - 11s 3ms/step\n",
      "Iteration: 4, precision: 0.93, recall: 0.94, F1: 0.93, accuracy: 0.96\n",
      "3400/3400 [==============================] - 11s 3ms/step\n",
      "Iteration: 5, precision: 0.93, recall: 0.93, F1: 0.93, accuracy: 0.96\n",
      "3400/3400 [==============================] - 12s 4ms/step\n",
      "Iteration: 6, precision: 0.91, recall: 0.95, F1: 0.93, accuracy: 0.95\n",
      "3400/3400 [==============================] - 10s 3ms/step\n",
      "Iteration: 7, precision: 0.94, recall: 0.94, F1: 0.94, accuracy: 0.96\n",
      "3400/3400 [==============================] - 11s 3ms/step\n",
      "Iteration: 8, precision: 0.93, recall: 0.94, F1: 0.93, accuracy: 0.96\n",
      "3400/3400 [==============================] - 11s 3ms/step\n",
      "Iteration: 9, precision: 0.93, recall: 0.94, F1: 0.94, accuracy: 0.96\n",
      "Average, precision: 92, recall: 93, F1: 93, accuracy: 95\n"
     ]
    }
   ],
   "source": [
    "loss = 'binary_crossentropy'\n",
    "num_of_test_samples = test_y.shape[0]\n",
    "batch_size = 120\n",
    "n = 10\n",
    "\n",
    "precision_total = 0\n",
    "recall_total = 0\n",
    "f1_total = 0\n",
    "accuracy_total = 0\n",
    "\n",
    "for i in range(n):\n",
    "    model = getLossModel2(train_X, train_y, loss)\n",
    "    test_mse = model.evaluate(test_X, test_y, verbose=1)\n",
    "    y_pred = model.predict_classes(test_X, num_of_test_samples // batch_size+1)\n",
    "    report = classification_report(test_y, y_pred, target_names=target_names, output_dict=True)\n",
    "    precision = report['macro avg']['precision']\n",
    "    recall = report['macro avg']['recall']\n",
    "    f1 = report['macro avg']['f1-score']\n",
    "    accuracy = report['accuracy']\n",
    "    \n",
    "    print(\"Iteration: %d, precision: %.2f, recall: %.2f, F1: %.2f, accuracy: %.2f\" % (i, precision, recall, f1, accuracy))\n",
    "    \n",
    "    precision_total += precision\n",
    "    recall_total += recall\n",
    "    f1_total += f1\n",
    "    accuracy_total += accuracy\n",
    "\n",
    "precision_total = precision_total / n * 100\n",
    "recall_total = recall_total / n * 100\n",
    "f1_total = f1_total / n * 100\n",
    "accuracy_total = accuracy_total / n * 100\n",
    "print(\"Average, precision: %d, recall: %d, F1: %d, accuracy: %d\" % (precision_total, recall_total, f1_total, accuracy_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
